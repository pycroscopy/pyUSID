

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Formalizing Data Processing using the Process Class &mdash; pyUSID 0.0.12 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=03e43079" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../_static/nbsphinx-code-cells.css?v=2aa19091" />

  
      <script src="../../_static/documentation_options.js?v=3bbcec59"></script>
      <script src="../../_static/doctools.js?v=9a2dae69"></script>
      <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
      <script src="https://cdn.jsdelivr.net/npm/@jupyter-widgets/html-manager@^1.0.1/dist/embed-amd.js"></script>
      <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
      <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="author" title="About these documents" href="../../about.html" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="prev" title="Utilities for writing h5USID files" href="hdf_utils_write.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            pyUSID
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">pyUSID</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../about.html">pyUSID</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../install.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq.html">Frequently asked questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../contact.html">Contact us</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../credits.html">Credits</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../scale_to_hpc.html">Scaling to Clusters</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../_autosummary/pyUSID.html">pyUSID</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Examples</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="index.html">User Guide</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="usi_dataset.html">The USIDataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="array_translator.html">ArrayTranslator for translating from proprietary file formats</a></li>
<li class="toctree-l2"><a class="reference internal" href="anc_build_utils.html">Utilities that assist in building USID Ancillary datasets manually</a></li>
<li class="toctree-l2"><a class="reference internal" href="hdf_utils_write.html">Utilities for writing h5USID files</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Formalizing Data Processing using the Process Class</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Introduction">Introduction</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#Components-of-pyUSID.Process">Components of pyUSID.Process</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Recommended-pre-requisite-reading">Recommended pre-requisite reading</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Example-problem">Example problem</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Import-necessary-packages">Import necessary packages</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Download-the-fitting-function-as-a-separate-file">Download the fitting function as a separate file</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#Defining-the-class">Defining the class</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#map_function()">map_function()</a></li>
<li class="toctree-l4"><a class="reference internal" href="#test()">test()</a></li>
<li class="toctree-l4"><a class="reference internal" href="#create_results_datasets()">create_results_datasets()</a></li>
<li class="toctree-l4"><a class="reference internal" href="#write_results_chunk()">write_results_chunk()</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#Comments">Comments</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#Use-the-class">Use the class</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Load-the-dataset">Load the dataset</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#Use-the-Process-class">Use the Process class</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#Instantiation">Instantiation</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id1">test()</a></li>
<li class="toctree-l4"><a class="reference internal" href="#compute()">compute()</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Visualize">Visualize</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Clean-up">Clean up</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#Flow-of-functions">Flow of functions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#init()">init()</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id2">test()</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id3">compute()</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#Tips-and-tricks">Tips and tricks</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#Advanced-examples">Advanced examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Integrating-into-your-personal-workflow">Integrating into your personal workflow</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Juggling-dimensions">Juggling dimensions</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Computing-on-chunks-instead-of-mapping">Computing on chunks instead of mapping</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">pyUSID</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="index.html">User Guide</a></li>
      <li class="breadcrumb-item active">Formalizing Data Processing using the Process Class</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/notebooks/user_guide/process.ipynb.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">matplotlib</span> inline
</pre></div>
</div>
</div>
<section id="Formalizing-Data-Processing-using-the-Process-Class">
<h1>Formalizing Data Processing using the Process Class<a class="headerlink" href="#Formalizing-Data-Processing-using-the-Process-Class" title="Link to this heading">¶</a></h1>
<p><strong>Suhas Somnath, Oak Ridge National Lab</strong></p>
<p><strong>Rajiv Giridharagopal, University of Washington</strong></p>
<p>Updated: 6/12/2020</p>
<p><strong>In this example, we will learn how to implement the pyUSID Process class. This method is ideal for situations where we want to parallel operate on a large dataset.</strong></p>
<section id="Introduction">
<h2>Introduction<a class="headerlink" href="#Introduction" title="Link to this heading">¶</a></h2>
<p>Most of code written for scientific research is in the form of single-use / one-off scripts due to a few common reasons:</p>
<ul class="simple">
<li><p>the author feels that it is the fastest mode to accomplishing a research task</p></li>
<li><p>the author feels that they are unlikely to perform the same operation again</p></li>
<li><p>the author does not anticipate the possibility that others may need to run their code</p></li>
</ul>
<p>However, more often than not, nearly all researchers have found that one or more of these assumptions fail and a lot of time is spent on fixing bugs and generalizing / formalizing code such that it can be shared or reused. Moreover, we live in an era of open science where the scientific community and an ever-increasing number of scientific journals are moving towards a paradigm where the data and code need to be made available with journal papers. Therefore, in the interest of saving time,
energy, and reputation, it makes a lot more sense to formalize (parts of) one’s data analysis code.</p>
<p>For many researchers, formalizing data processing or analysis may seem like a daunting task due to the complexity of and the number of sub-operations that need to performed. <code class="docutils literal notranslate"><span class="pre">pyUSID.Process</span></code> greatly simplifies the process of formalizing code by lifting or reducing the burden of implementing important, yet tedious tasks and considerations such as:</p>
<ul class="simple">
<li><p><strong>memory management</strong> - reading chunks of datasets that can be processed with the available memory, something very crucial for very large datasets that cannot entirely fit into the computer’s memory</p></li>
<li><p><strong>Scalable parallel computing</strong> -</p>
<ul>
<li><p>On personal computers - considerate CPU usage - Process will use all but one or two CPU cores for the (parallel) computation, which allows the user to continue using the computer for other activities such as reading mail, etc.</p></li>
<li><p>New in pyUSID v. 0.0.5 - Ability to scale to multiple computers in a cluster. The Process class can scale the same scientific code written for personal computers to use multiple computers (or nodes) on a high performance computing (HPC) resource or a cloud-based cluster to dramatically reduce the computational time</p></li>
</ul>
</li>
<li><p><strong>pausing and resuming computation</strong> - interrupting and resuming the computation at a more convenient time, something that is especially valuable for lengthy computations.</p></li>
<li><p><strong>avoiding repeated computation and returning existing results</strong> - pyUSID.Process will return existing results computed using the exact same parameters instead of re-computing and storing duplicate copies of the same results.</p></li>
<li><p><strong>testing before computation</strong> - checking the processing / analysis on a single unit (typically a single pixel) of data before the entire data is processed. This is particularly useful for lengthy computations.</p></li>
</ul>
<p>Using <code class="docutils literal notranslate"><span class="pre">pyUSID.Process</span></code>, the user only needs to address the following basic operations:</p>
<ol class="arabic simple">
<li><p>Reading data from file</p></li>
<li><p>Computation on a single unit of data</p></li>
<li><p>Writing results to disk</p></li>
</ol>
<section id="Components-of-pyUSID.Process">
<h3>Components of pyUSID.Process<a class="headerlink" href="#Components-of-pyUSID.Process" title="Link to this heading">¶</a></h3>
<p>The most important functions in the Process class are:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">__init__()</span></code> - instantiates a ‘Process’ object of this class after validating the inputs.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">_create_results_datasets()</span></code> - creates the HDF5 datasets and Group(s) to store the results.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">_map_function()</span></code> - the operation that will per be performed on each element in the dataset.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">test()</span></code> - This simple function lets the user test the <code class="docutils literal notranslate"><span class="pre">map_function</span></code> on a unit of data (a single pixel typically) to see if it returns the desired results. It saves a lot of computational time by allowing the user to spot-check results before computing on the entire dataset</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">_read_data_chunk()</span></code> - reads the input data from one or more datasets.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">_write_results_chunk()</span></code> - writes the computed results back to the file</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">_unit_computation()</span></code> - Defines how to process a chunk (multiple units) of data. This allows room for pre-processing of input data and post-processing of results if necessary. If neither are required, this function essentially applies the parallel computation on <code class="docutils literal notranslate"><span class="pre">_map_function()</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">compute()</span></code> - this does the bulk of the work of (iteratively) reading a chunk of data &gt;&gt; processing in parallel via <code class="docutils literal notranslate"><span class="pre">_unit_computation()</span></code> &gt;&gt; calling <code class="docutils literal notranslate"><span class="pre">_write_results_chunk()</span></code> to write data. Most sub-classes, including the one below, do not need to extend / modify this function.</p></li>
</ul>
<p>See the “Flow of Functions” section near the bottom for a bit more detail.</p>
</section>
<section id="Recommended-pre-requisite-reading">
<h3>Recommended pre-requisite reading<a class="headerlink" href="#Recommended-pre-requisite-reading" title="Link to this heading">¶</a></h3>
<ul class="simple">
<li><p><a class="reference external" href="https://pycroscopy.github.io/USID/usid_model.html">Universal Spectroscopic and Imaging Data (USID) model</a></p></li>
<li><p><a class="reference external" href="./h5py_primer.html">Crash course on HDF5 and h5py</a></p></li>
<li><p>Utilities for <a class="reference external" href="./hdf_utils_read.html">reading</a> and <a class="reference external" href="./plot_hdf_utils_write.html">writing</a> h5USID files using pyUSID</p></li>
<li><p>Crash course on <a class="reference external" href="https://pycroscopy.github.io/sidpy/notebooks/01_parallel_computing/parallel_compute.html">parallel processing</a></p></li>
</ul>
</section>
<section id="Example-problem">
<h3>Example problem<a class="headerlink" href="#Example-problem" title="Link to this heading">¶</a></h3>
<p>We will be working with a Band Excitation Piezoresponse Force Microscopy (BE-PFM) imaging dataset acquired from advanced atomic force microscopes. In this dataset, a spectra was collected for each position in a two dimensional grid of spatial locations. Thus, this is a three dimensional dataset that has been flattened to a two dimensional matrix in accordance with the USID model.</p>
<p>This example is based on the parallel computing primer where we searched for the peak of each spectra in a dataset. While that example focused on comparing serial and parallel computing, we will focus on demonstrating the simplicity with which such a data analysis algorithm can be formalized.</p>
<p>This example is a simplification of the pycroscopy.analysis.BESHOFitter class in our sister project - Pycroscopy.</p>
</section>
<section id="Import-necessary-packages">
<h3>Import necessary packages<a class="headerlink" href="#Import-necessary-packages" title="Link to this heading">¶</a></h3>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">__future__</span><span class="w"> </span><span class="kn">import</span> <span class="n">division</span><span class="p">,</span> <span class="n">print_function</span><span class="p">,</span> <span class="n">absolute_import</span><span class="p">,</span> <span class="n">unicode_literals</span>

<span class="c1"># The package for accessing files in directories, etc.:</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>

<span class="c1"># Warning package in case something goes wrong</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">warnings</span><span class="w"> </span><span class="kn">import</span> <span class="n">warn</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">subprocess</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">sys</span>

<span class="k">def</span><span class="w"> </span><span class="nf">install</span><span class="p">(</span><span class="n">package</span><span class="p">):</span>
    <span class="n">subprocess</span><span class="o">.</span><span class="n">call</span><span class="p">([</span><span class="n">sys</span><span class="o">.</span><span class="n">executable</span><span class="p">,</span> <span class="s2">&quot;-m&quot;</span><span class="p">,</span> <span class="s2">&quot;pip&quot;</span><span class="p">,</span> <span class="s2">&quot;install&quot;</span><span class="p">,</span> <span class="n">package</span><span class="p">])</span>
<span class="c1"># Package for downloading online files:</span>
<span class="k">try</span><span class="p">:</span>
    <span class="c1"># This package is not part of anaconda and may need to be installed.</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">wget</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
    <span class="n">warn</span><span class="p">(</span><span class="s1">&#39;wget not found.  Will install with pip.&#39;</span><span class="p">)</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">pip</span>
    <span class="n">install</span><span class="p">(</span><span class="s1">&#39;wget&#39;</span><span class="p">)</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">wget</span>

<span class="c1"># The mathematical computation package:</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="c1"># The package used for creating and manipulating HDF5 files:</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">h5py</span>

<span class="c1"># Packages for plotting:</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="c1"># import sidpy - supporting package for pyUSID:</span>
<span class="k">try</span><span class="p">:</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">sidpy</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
    <span class="n">warn</span><span class="p">(</span><span class="s1">&#39;sidpy not found.  Will install with pip.&#39;</span><span class="p">)</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">pip</span>
    <span class="n">install</span><span class="p">(</span><span class="s1">&#39;sidpy&#39;</span><span class="p">)</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">sidpy</span>

<span class="c1"># Finally import pyUSID:</span>
<span class="k">try</span><span class="p">:</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">pyUSID</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">usid</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
    <span class="n">warn</span><span class="p">(</span><span class="s1">&#39;pyUSID not found.  Will install with pip.&#39;</span><span class="p">)</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">pip</span>
    <span class="n">install</span><span class="p">(</span><span class="s1">&#39;pyUSID&#39;</span><span class="p">)</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">pyUSID</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">usid</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
//anaconda/lib/python3.5/site-packages/pyUSID/viz/__init__.py:18: FutureWarning: Please use sidpy.viz.plot_utils instead of pyUSID.viz.plot_utils. pyUSID.plot_utils will be removed in a future release of pyUSID
  FutureWarning)
</pre></div></div>
</div>
</section>
<section id="Download-the-fitting-function-as-a-separate-file">
<h3>Download the fitting function as a separate file<a class="headerlink" href="#Download-the-fitting-function-as-a-separate-file" title="Link to this heading">¶</a></h3>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">peak_func_file</span> <span class="o">=</span> <span class="s1">&#39;peak_finding.py&#39;</span>
<span class="n">url</span> <span class="o">=</span> <span class="s1">&#39;https://raw.githubusercontent.com/pycroscopy/pyUSID/master/notebooks/user_guide/supporting_docs/peak_finding.py&#39;</span>
<span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">peak_func_file</span><span class="p">):</span>
    <span class="n">os</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">peak_func_file</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">wget</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">peak_func_file</span><span class="p">,</span> <span class="n">bar</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="c1"># the scientific function</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">peak_finding</span><span class="w"> </span><span class="kn">import</span> <span class="n">find_all_peaks</span>
</pre></div>
</div>
</div>
<p>The goal is to <strong>find the amplitude at the peak in each spectra</strong>. Clearly, the operation of finding the peak in one spectra is independent of the same operation on another spectra. Thus, we could divide the dataset in to N parts and use N CPU cores to compute the results much faster than it would take a single core to compute the results. Such problems are ideally suited for making use of all the advanced functionalities in the Process class.</p>
</section>
</section>
<section id="Defining-the-class">
<h2>Defining the class<a class="headerlink" href="#Defining-the-class" title="Link to this heading">¶</a></h2>
<p>In order to solve our problem, we would need to implement a <code class="docutils literal notranslate"><span class="pre">sub-class</span></code> of pyUSID.Process or in other words - <strong>extend pyUSID.Process</strong>. As mentioned above, the pyUSID.Process class already generalizes several important components of data processing. We only need to extend this class by implementing the science-specific functionality. The rest of the capabilities will be <strong>inherited</strong> from pyUSID.Process.</p>
<p>Lets think about what operations need be performed for each of the core Process functions listed above.</p>
<section id="map_function()">
<h3>map_function()<a class="headerlink" href="#map_function()" title="Link to this heading">¶</a></h3>
<p>The most important component in our new Process class is the unit computation that needs to be performed on each spectra. <code class="docutils literal notranslate"><span class="pre">map_function()</span></code> needs to take as input a single spectra and return the amplitude at the peak (a single value). The <code class="docutils literal notranslate"><span class="pre">compute()</span></code> and <code class="docutils literal notranslate"><span class="pre">unit_computation()</span></code> will handle the parallelization.</p>
<p>The scipy package has a very handy function called <em>find_peaks_cwt()</em> that facilitates the search for one or more peaks in a spectrum. We will be using a simplified function called <em>find_all_peaks()</em>. The exact methodology for finding the peaks is not of interest for this particular example. However, this function finds the index of 0 or more peaks in the spectra. We only expect one peak at the center of the spectra. Therefore, we can use the <code class="docutils literal notranslate"><span class="pre">find_all_peaks()</span></code> function to find the peaks and
address those situations when too few or too many (&gt; 1) peaks are found in a single spectra. Finally, we need to use the index of the peak to find the amplitude from the spectra.</p>
<div class="admonition note">
<div class="admonition-title fa fa-exclamation-circle"><h4></div><p>Note</p>
</h4></div>
<p><code class="docutils literal notranslate"><span class="pre">_map_function()</span></code> must be marked as a <a class="reference external" href="https://www.geeksforgeeks.org/class-method-vs-static-method-python/">static method</a> instead of the default <code class="docutils literal notranslate"><span class="pre">class</span> <span class="pre">method</span></code>. This means that <code class="docutils literal notranslate"><span class="pre">_map_function()</span></code> should function exactly the same if it were outside the class we are defining. In other words, it should not make any references to properties or functions of the class such as <code class="docutils literal notranslate"><span class="pre">self.my_important_variable</span></code> or <code class="docutils literal notranslate"><span class="pre">self.some_function()</span></code>.</p>
</section>
<section id="test()">
<h3>test()<a class="headerlink" href="#test()" title="Link to this heading">¶</a></h3>
<p>A useful test function should be able to find the peak amplitude for any single spectra in the dataset. So, given the index of a pixel (provided by the user), we should perform two operations:</p>
<ul class="simple">
<li><p>read the spectra corresponding to that index from the HDF5 dataset</p></li>
<li><p>apply the <code class="docutils literal notranslate"><span class="pre">map_function()</span></code> to this spectra and return the result.</p></li>
</ul>
<p>The goal here is to load the smallest necessary portion of data from the HDF5 dataset to memory and test it against the <code class="docutils literal notranslate"><span class="pre">map_function()</span></code></p>
</section>
<section id="create_results_datasets()">
<h3>create_results_datasets()<a class="headerlink" href="#create_results_datasets()" title="Link to this heading">¶</a></h3>
<p>Every Process involves a few tasks for this function:</p>
<ul class="simple">
<li><p>the creation of a HDF5 group to hold the datasets containing the results - pyUSID.hdf_utils has a handy function that takes care of this.</p></li>
<li><p>storing any relevant metadata regarding this processing as attributes of the HDF5 group for provenance, traceability , and reproducibility.</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">last_pixel</span></code> is a reserved attribute that serves as a flag indicating the last pixel that was successfully processed and written to the results dataset. This attribute is key for resuming partial computations.</p></li>
</ul>
</li>
<li><p>the creation of HDF5 dataset(s) to hold the results. <code class="docutils literal notranslate"><span class="pre">map_function()</span></code> takes a spectra (1D array) and returns the amplitude (a single value). Thus the input dataset (position, spectra) will be reduced to (position, 1). So, we only need to create a single empty dataset to hold the results.</p></li>
</ul>
<p>We just need to ensure that we have a reference to the results dataset so that we can populate it with the results.</p>
</section>
<section id="write_results_chunk()">
<h3>write_results_chunk()<a class="headerlink" href="#write_results_chunk()" title="Link to this heading">¶</a></h3>
<p>The result of <code class="docutils literal notranslate"><span class="pre">compute()</span></code> will be a list of amplitude values. All we need to do is:</p>
<ul class="simple">
<li><p>call the <code class="docutils literal notranslate"><span class="pre">self._get_pixels_in_current_batch()</span></code> to find out which pixels were processed in this batch</p></li>
<li><p>write the results into the HDF5 dataset</p></li>
</ul>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">PeakFinder</span><span class="p">(</span><span class="n">usid</span><span class="o">.</span><span class="n">Process</span><span class="p">):</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">h5_main</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Applies Bayesian Inference to General Mode IV (G-IV) data to extract the true current</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        h5_main : h5py.Dataset object</span>
<span class="sd">            Dataset to process</span>
<span class="sd">        kwargs : dict</span>
<span class="sd">            Other parameters specific to the Process class and nuanced bayesian_inference parameters</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">PeakFinder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">h5_main</span><span class="p">,</span> <span class="s1">&#39;Peak_Finding&#39;</span><span class="p">,</span>
                                         <span class="n">parms_dict</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;algorithm&#39;</span><span class="p">:</span> <span class="s1">&#39;find_all_peaks&#39;</span><span class="p">},</span>
                                         <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">test</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pixel_ind</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Test the algorithm on a single pixel</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        pixel_ind : uint</span>
<span class="sd">            Index of the pixel in the dataset that the process needs to be tested on.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># First read the HDF5 dataset to get the spectra for this pixel</span>
        <span class="n">spectra</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">h5_main</span><span class="p">[</span><span class="n">pixel_ind</span><span class="p">]</span>
        <span class="c1"># Next, apply the map function to the spectra. done!</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_map_function</span><span class="p">(</span><span class="n">spectra</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_create_results_datasets</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Creates the datasets an Groups necessary to store the results.</span>
<span class="sd">        There are only THREE operations happening in this function:</span>
<span class="sd">        1. Creation of HDF5 group to hold results</span>
<span class="sd">        2. Writing relevant metadata to this HDF5 group</span>
<span class="sd">        3. Creation of a HDF5 dataset to hold results</span>

<span class="sd">        Please see examples on utilities for writing h5USID files for more information</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># 1. create a HDF5 group to hold the results</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">h5_results_grp</span> <span class="o">=</span> <span class="n">usid</span><span class="o">.</span><span class="n">hdf_utils</span><span class="o">.</span><span class="n">create_results_group</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">h5_main</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">process_name</span><span class="p">)</span>

        <span class="c1"># 2. Write relevant metadata to the group</span>
        <span class="n">sidpy</span><span class="o">.</span><span class="n">hdf_utils</span><span class="o">.</span><span class="n">write_simple_attrs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">h5_results_grp</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">parms_dict</span><span class="p">)</span>

        <span class="c1"># Explicitly stating all the inputs to write_main_dataset</span>
        <span class="c1"># The process will reduce the spectra at each position to a single value</span>
        <span class="c1"># Therefore, the result is a 2D dataset with the same number of positions as self.h5_main</span>
        <span class="n">results_shape</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">h5_main</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">results_dset_name</span> <span class="o">=</span> <span class="s1">&#39;Peak_Response&#39;</span>
        <span class="n">results_quantity</span> <span class="o">=</span> <span class="s1">&#39;Amplitude&#39;</span>
        <span class="n">results_units</span> <span class="o">=</span> <span class="s1">&#39;V&#39;</span>
        <span class="n">pos_dims</span> <span class="o">=</span> <span class="kc">None</span> <span class="c1"># Reusing those linked to self.h5_main</span>
        <span class="n">spec_dims</span> <span class="o">=</span> <span class="n">usid</span><span class="o">.</span><span class="n">Dimension</span><span class="p">(</span><span class="s1">&#39;Empty&#39;</span><span class="p">,</span> <span class="s1">&#39;a. u.&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

        <span class="c1"># 3. Create an empty results dataset that will hold all the results</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">h5_results</span> <span class="o">=</span> <span class="n">usid</span><span class="o">.</span><span class="n">hdf_utils</span><span class="o">.</span><span class="n">write_main_dataset</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">h5_results_grp</span><span class="p">,</span> <span class="n">results_shape</span><span class="p">,</span> <span class="n">results_dset_name</span><span class="p">,</span>
                                                          <span class="n">results_quantity</span><span class="p">,</span> <span class="n">results_units</span><span class="p">,</span> <span class="n">pos_dims</span><span class="p">,</span> <span class="n">spec_dims</span><span class="p">,</span>
                                                          <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>
                                                          <span class="n">h5_pos_inds</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">h5_main</span><span class="o">.</span><span class="n">h5_pos_inds</span><span class="p">,</span>
                                                          <span class="n">h5_pos_vals</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">h5_main</span><span class="o">.</span><span class="n">h5_pos_vals</span><span class="p">)</span>
        <span class="c1"># Note that this function automatically creates the ancillary datasets and links them.</span>

        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Finished creating datasets&#39;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_write_results_chunk</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Write the computed results back to the H5</span>
<span class="sd">        In this case, there isn&#39;t any more additional post-processing required</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Find out the positions to write to:</span>
        <span class="n">pos_in_batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_pixels_in_current_batch</span><span class="p">()</span>

        <span class="c1"># write the results to the file</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">h5_results</span><span class="p">[</span><span class="n">pos_in_batch</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_results</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_map_function</span><span class="p">(</span><span class="n">spectra</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This is the function that will be applied to each pixel in the dataset.</span>
<span class="sd">        It&#39;s job is to demonstrate what needs to be done for each pixel in the dataset.</span>
<span class="sd">        pyUSID.Process will handle the parallel computation and memory management</span>

<span class="sd">        As in typical scientific problems, the results from find_all_peaks() need to be</span>
<span class="sd">        post-processed</span>

<span class="sd">        In this case, the find_all_peaks() function can sometimes return 0 or more than one peak</span>
<span class="sd">        for spectra that are very noisy</span>

<span class="sd">        Knowing that the peak is typically at the center of the spectra,</span>
<span class="sd">        we return the central index when no peaks were found</span>
<span class="sd">        Or the index closest to the center when multiple peaks are found</span>

<span class="sd">        Finally once we have a single index, we need to index the spectra by that index</span>
<span class="sd">        in order to get the amplitude at that frequency.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">peak_inds</span> <span class="o">=</span> <span class="n">find_all_peaks</span><span class="p">(</span><span class="n">spectra</span><span class="p">,</span> <span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">60</span><span class="p">],</span> <span class="n">num_steps</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>

        <span class="n">central_ind</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">spectra</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">peak_inds</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># too few peaks</span>
            <span class="c1"># set peak to center of spectra</span>
            <span class="n">val</span> <span class="o">=</span> <span class="n">central_ind</span>
        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">peak_inds</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="c1"># too many peaks</span>
            <span class="c1"># set to peak closest to center of spectra</span>
            <span class="n">dist</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">peak_inds</span> <span class="o">-</span> <span class="n">central_ind</span><span class="p">)</span>
            <span class="n">val</span> <span class="o">=</span> <span class="n">peak_inds</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">dist</span><span class="p">)]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># normal situation</span>
            <span class="n">val</span> <span class="o">=</span> <span class="n">peak_inds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="c1"># Finally take the amplitude of the spectra at this index</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">spectra</span><span class="p">[</span><span class="n">val</span><span class="p">])</span>
</pre></div>
</div>
</div>
</section>
</section>
<section id="Comments">
<h2>Comments<a class="headerlink" href="#Comments" title="Link to this heading">¶</a></h2>
<ul class="simple">
<li><p>The class appears to be large mainly because of comments that explain what each line of code is doing.</p></li>
<li><p>Several functions of pyUSID.Process such as <code class="docutils literal notranslate"><span class="pre">__init__()</span></code> and <code class="docutils literal notranslate"><span class="pre">compute()</span></code> were inherited from the pyUSID.Process class.</p></li>
<li><p>In simple cases such as this, we don’t even have to implement a function to read the data from the dataset since pyUSID.Process automatically calculates how much of the data iss safe to load into memory. In this case, the dataset is far smaller than the computer memory, so the entire dataset can be loaded and processed at once.</p></li>
<li><p>In this example, we did not need any pre-processing or post-processing of results but those can be implemented too if necessary.</p></li>
<li><p>The majority of the code in this class would have to be written regardless of whether the intention is formalize the data processing or not. In fact, we would argue that <strong>more</strong> code may need to be written than what is shown below if one were <strong>not</strong> formalizing the data processing (data reading, parallel computing, memory management, etc.)</p></li>
<li><p>This is the simplest possible implementation of Process. Certain features such as checking for existing results and resuming partial computations have not been shown in this example.</p></li>
</ul>
<section id="Use-the-class">
<h3>Use the class<a class="headerlink" href="#Use-the-class" title="Link to this heading">¶</a></h3>
<p>Now that the class has been written, it can be applied to an actual dataset.</p>
</section>
<section id="Load-the-dataset">
<h3>Load the dataset<a class="headerlink" href="#Load-the-dataset" title="Link to this heading">¶</a></h3>
<p>In order to demonstrate this Process class, we will be using a real experimental dataset that is available on the pyUSID GitHub project. First, lets download this file from Github:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">h5_path</span> <span class="o">=</span> <span class="s1">&#39;temp.h5&#39;</span>
<span class="n">url</span> <span class="o">=</span> <span class="s1">&#39;https://raw.githubusercontent.com/pycroscopy/pyUSID/master/data/BELine_0004.h5&#39;</span>
<span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">h5_path</span><span class="p">):</span>
    <span class="n">os</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">h5_path</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">wget</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">h5_path</span><span class="p">,</span> <span class="n">bar</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Lets open the file in an editable (r+) mode and look at the contents:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">h5_file</span> <span class="o">=</span> <span class="n">h5py</span><span class="o">.</span><span class="n">File</span><span class="p">(</span><span class="n">h5_path</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;r+&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;File contents:</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">sidpy</span><span class="o">.</span><span class="n">hdf_utils</span><span class="o">.</span><span class="n">print_tree</span><span class="p">(</span><span class="n">h5_file</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>The focus of this example is not on the data storage or formatting but rather on demonstrating our new Process class so lets dive straight into the main dataset that requires analysis of the spectra:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">h5_chan_grp</span> <span class="o">=</span> <span class="n">h5_file</span><span class="p">[</span><span class="s1">&#39;Measurement_000/Channel_000&#39;</span><span class="p">]</span>

<span class="c1"># Accessing the dataset of interest:</span>
<span class="n">h5_main</span> <span class="o">=</span> <span class="n">usid</span><span class="o">.</span><span class="n">USIDataset</span><span class="p">(</span><span class="n">h5_chan_grp</span><span class="p">[</span><span class="s1">&#39;Raw_Data&#39;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">The main dataset:</span><span class="se">\n</span><span class="s1">------------------------------------&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">h5_main</span><span class="p">)</span>

<span class="c1"># Extract some metadata:</span>
<span class="n">num_rows</span><span class="p">,</span> <span class="n">num_cols</span> <span class="o">=</span> <span class="n">h5_main</span><span class="o">.</span><span class="n">pos_dim_sizes</span>
<span class="n">freq_vec</span> <span class="o">=</span> <span class="n">h5_main</span><span class="o">.</span><span class="n">get_spec_values</span><span class="p">(</span><span class="s1">&#39;Frequency&#39;</span><span class="p">)</span> <span class="o">*</span> <span class="mf">1E-3</span>
</pre></div>
</div>
</div>
</section>
</section>
<section id="Use-the-Process-class">
<h2>Use the Process class<a class="headerlink" href="#Use-the-Process-class" title="Link to this heading">¶</a></h2>
<section id="Instantiation">
<h3>Instantiation<a class="headerlink" href="#Instantiation" title="Link to this heading">¶</a></h3>
<p>Note that the instantiation of the new <code class="docutils literal notranslate"><span class="pre">PeakFinder</span></code> Process class only requires that we supply the main dataset on which the computation will be performed:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fitter</span> <span class="o">=</span> <span class="n">PeakFinder</span><span class="p">(</span><span class="n">h5_main</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
<section id="id1">
<h3>test()<a class="headerlink" href="#id1" title="Link to this heading">¶</a></h3>
<p>As advised, lets test the <code class="docutils literal notranslate"><span class="pre">PeakFinder</span></code> on an example pixel:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">row_ind</span><span class="p">,</span> <span class="n">col_ind</span> <span class="o">=</span> <span class="mi">103</span><span class="p">,</span> <span class="mi">19</span>
<span class="n">pixel_ind</span> <span class="o">=</span> <span class="n">col_ind</span> <span class="o">+</span> <span class="n">row_ind</span> <span class="o">*</span> <span class="n">num_cols</span>

<span class="c1"># Testing is as simple as supplying a pixel index</span>
<span class="n">amplitude</span> <span class="o">=</span> <span class="n">fitter</span><span class="o">.</span><span class="n">test</span><span class="p">(</span><span class="n">pixel_ind</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Now, let’s visualize the results of the test:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">spectra</span> <span class="o">=</span> <span class="n">h5_main</span><span class="p">[</span><span class="n">pixel_ind</span><span class="p">]</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">axis</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">freq_vec</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">spectra</span><span class="p">),</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>
<span class="n">axis</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">amplitude</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">axis</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Frequency (kHz)&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">axis</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Amplitude (V)&#39;</span><span class="p">)</span>
<span class="n">axis</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mf">1.1</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">spectra</span><span class="p">))])</span>
<span class="n">axis</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;PeakFinder applied to pixel</span><span class="se">\n</span><span class="s1">at row: </span><span class="si">{}</span><span class="s1">, col: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">row_ind</span><span class="p">,</span> <span class="n">col_ind</span><span class="p">),</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">);</span>
</pre></div>
</div>
</div>
<p>If we weren’t happy with the results, we could tweak some parameters when initializing the <code class="docutils literal notranslate"><span class="pre">PeakFinder</span></code> object and try again. However, for the sake of simplicity, we don’t have any parameters we can / want to adjust in this case. So, lets proceed.</p>
</section>
<section id="compute()">
<h3>compute()<a class="headerlink" href="#compute()" title="Link to this heading">¶</a></h3>
<p>Now that we know that the <code class="docutils literal notranslate"><span class="pre">PeakFinder</span></code> appears to be performing as expected, we can apply the amplitude finding</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">h5_results_grp</span> <span class="o">=</span> <span class="n">fitter</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">h5_results_grp</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Lets take a look again at the file contents. We should be seeing a new HDF5 group called <code class="docutils literal notranslate"><span class="pre">Raw_Data-Peak_Finding_000</span></code> and three datasets within the group. Among the datasets is <code class="docutils literal notranslate"><span class="pre">Peak_Response</span></code> that contains the peak amplitudes we are interested in.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sidpy</span><span class="o">.</span><span class="n">hdf_utils</span><span class="o">.</span><span class="n">print_tree</span><span class="p">(</span><span class="n">h5_file</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Lets look at this <code class="docutils literal notranslate"><span class="pre">Peak_Response</span></code> dataset:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">h5_peak_amps</span> <span class="o">=</span> <span class="n">usid</span><span class="o">.</span><span class="n">USIDataset</span><span class="p">(</span><span class="n">h5_results_grp</span><span class="p">[</span><span class="s1">&#39;Peak_Response&#39;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">h5_peak_amps</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
<section id="Visualize">
<h3>Visualize<a class="headerlink" href="#Visualize" title="Link to this heading">¶</a></h3>
<p>Since <code class="docutils literal notranslate"><span class="pre">Peak_Response</span></code> is a USIDataset, we could use its built-in <code class="docutils literal notranslate"><span class="pre">visualize()</span></code> function:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">h5_peak_amps</span><span class="o">.</span><span class="n">visualize</span><span class="p">()</span>
</pre></div>
</div>
</div>
</section>
<section id="Clean-up">
<h3>Clean up<a class="headerlink" href="#Clean-up" title="Link to this heading">¶</a></h3>
<p>Finally lets close and delete the example HDF5 file</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">h5_file</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
<span class="n">os</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">h5_path</span><span class="p">)</span>
<span class="n">os</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">peak_func_file</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
</section>
<section id="Flow-of-functions">
<h2>Flow of functions<a class="headerlink" href="#Flow-of-functions" title="Link to this heading">¶</a></h2>
<p>By default, very few functions (<code class="docutils literal notranslate"><span class="pre">test()</span></code>, <code class="docutils literal notranslate"><span class="pre">compute()</span></code>) are exposed to users. This means that one of these functions calls a chain of the other functions in the class.</p>
<section id="init()">
<h3>init()<a class="headerlink" href="#init()" title="Link to this heading">¶</a></h3>
<p>Instantiating the class via something like: <code class="docutils literal notranslate"><span class="pre">fitter</span> <span class="pre">=</span> <span class="pre">PeakFinder(h5_main)</span></code> happens in two parts:</p>
<ol class="arabic simple">
<li><p>First the subclass (<code class="docutils literal notranslate"><span class="pre">PeakFinder</span></code>) calls the initialization function in <code class="docutils literal notranslate"><span class="pre">Process</span></code> to let it run some checks:</p></li>
</ol>
<ul class="simple">
<li><p>Check if the provided <code class="docutils literal notranslate"><span class="pre">h5_main</span></code> is indeed a <code class="docutils literal notranslate"><span class="pre">Main</span></code> dataset</p></li>
<li><p>call <code class="docutils literal notranslate"><span class="pre">set_memory_and_cores()</span></code> to figure out how many pixels can be read into memory at any given time</p></li>
<li><p>Initialize some basic variables</p></li>
</ul>
<ol class="arabic simple" start="2">
<li><p>Next, the subclass continues any further validation / checks / initialization - this was not implemented for <code class="docutils literal notranslate"><span class="pre">PeakFinder</span></code> but here are some things that can be done:</p>
<ul class="simple">
<li><p>Find HDF5 groups which either have partial or fully computed results already for the same parameters by calling <code class="docutils literal notranslate"><span class="pre">check_for_duplicates()</span></code></p></li>
</ul>
</li>
</ol>
</section>
<section id="id2">
<h3>test()<a class="headerlink" href="#id2" title="Link to this heading">¶</a></h3>
<p>This function only calls the <code class="docutils literal notranslate"><span class="pre">map_function()</span></code> by definition</p>
</section>
<section id="id3">
<h3>compute()<a class="headerlink" href="#id3" title="Link to this heading">¶</a></h3>
<p>Here is how <code class="docutils literal notranslate"><span class="pre">compute()</span></code> works:</p>
<ul class="simple">
<li><p>Check if you can return existing results for the requested computation and return if available by calling either:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">get_existing_datasets()</span></code> - reads all necessary parameters and gets references to the HDF5 datasets that should contain the results</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">use_partial_computation()</span></code> - pick the first partially computed results group that was discovered by <code class="docutils literal notranslate"><span class="pre">check_for_duplicates()</span></code></p></li>
</ul>
</li>
<li><p>call <code class="docutils literal notranslate"><span class="pre">create_results_datasets()</span></code> to create the HDF5 datasets and group objects</p></li>
<li><p>read the first chunk of data via <code class="docutils literal notranslate"><span class="pre">read_data_chunk()</span></code> into <code class="docutils literal notranslate"><span class="pre">self.data</span></code></p></li>
<li><p>Until the source dataset is fully read (<code class="docutils literal notranslate"><span class="pre">self.data</span> <span class="pre">is</span> <span class="pre">not</span> <span class="pre">None</span></code>), do:</p>
<ul>
<li><p>call <code class="docutils literal notranslate"><span class="pre">unit_computation()</span></code> on <code class="docutils literal notranslate"><span class="pre">self.data</span></code></p>
<ul>
<li><p>By default <code class="docutils literal notranslate"><span class="pre">unit_computation()</span></code> just maps <code class="docutils literal notranslate"><span class="pre">map_function()</span></code> onto <code class="docutils literal notranslate"><span class="pre">self.data</span></code></p></li>
<li><p>If you need to pass specific arguments, you may need to implement it directly. See “Advanced Examples”</p></li>
</ul>
</li>
<li><p>call <code class="docutils literal notranslate"><span class="pre">write_results_chunk()</span></code> to write <code class="docutils literal notranslate"><span class="pre">self._results</span></code> into the HDF5 datasets</p></li>
<li><p>read the next chunk of data into <code class="docutils literal notranslate"><span class="pre">self.data</span></code></p></li>
</ul>
</li>
</ul>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>use_partial_computation()</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Not used in <code class="docutils literal notranslate"><span class="pre">PeakFinder</span></code> but this function can be called to manually specify an HDF5 group containing partial</p></td>
</tr>
<tr class="row-odd"><td><p>results</p></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="Tips-and-tricks">
<h2>Tips and tricks<a class="headerlink" href="#Tips-and-tricks" title="Link to this heading">¶</a></h2>
<p>Here we will cover a few common use-cases that will hopefully guide you in structuring your computational problem</p>
<section id="Advanced-examples">
<h3>Advanced examples<a class="headerlink" href="#Advanced-examples" title="Link to this heading">¶</a></h3>
<p>Please see the following pycroscopy classes to learn more about the advanced functionalities such as resuming computations, checking of existing results, using unit_computation(), etc.:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/pycroscopy/pycroscopy/blob/master/pycroscopy/processing/signal_filter.py">SignalFilter</a></p></li>
<li><p><a class="reference external" href="https://github.com/pycroscopy/BGlib/blob/master/BGlib/gmode/analysis/giv_bayesian.py">GIVBayesian</a></p></li>
<li><p><a class="reference external" href="https://github.com/rajgiriUW/ffta/blob/master/ffta/hdf_utils/process.py">FFTA</a></p></li>
</ul>
<p>These classes work on personal computers as well as a cluster of computers (e.g. - a high-performance computing cluster).</p>
</section>
<section id="Integrating-into-your-personal-workflow">
<h3>Integrating into your personal workflow<a class="headerlink" href="#Integrating-into-your-personal-workflow" title="Link to this heading">¶</a></h3>
<p>As an example of how to integrate with an outside codebase, the package <a class="reference external" href="https://github.com/rajgiriUW/ffta/blob/master/ffta/hdf_utils/process.py">FFTA</a> implements its own Process class for parallel computation. There you can see how to pass arguments to <code class="docutils literal notranslate"><span class="pre">unit_computation()</span></code></p>
</section>
<section id="Juggling-dimensions">
<h3>Juggling dimensions<a class="headerlink" href="#Juggling-dimensions" title="Link to this heading">¶</a></h3>
<p>We intentionally chose a simple example above to quickly illustrate the main components / philosophy of the Process class. The above example had two position dimensions collapsed into the first axis of the dataset and a single spectroscopic dimension (<code class="docutils literal notranslate"><span class="pre">Frequency</span></code>). What if the spectra were acquired as a function of other variables such as a <code class="docutils literal notranslate"><span class="pre">DC</span> <span class="pre">bias</span></code>? In other words, the dataset would now have N spectra per location. In such cases, the dataset would have 2 spectroscopic dimensions:
<code class="docutils literal notranslate"><span class="pre">Frequency</span></code> and <code class="docutils literal notranslate"><span class="pre">DC</span> <span class="pre">bias</span></code>. We cannot therefore simply map the <code class="docutils literal notranslate"><span class="pre">map_function()</span></code> to the data in every pixel. This is because the <code class="docutils literal notranslate"><span class="pre">map_function()</span></code> expects to work over a single spectra whereas we now have N spectra per pixel. Contrary to what one would assume, we do not need to throw away all the code we wrote above. We only need to add code to juggle / move the dimensions around till the problem looks similar to what we had above.</p>
<p>In other words, the above problem was written for a dataset of shape <code class="docutils literal notranslate"><span class="pre">(P,</span> <span class="pre">S)</span></code> where <code class="docutils literal notranslate"><span class="pre">P</span></code> is the number of positions and <code class="docutils literal notranslate"><span class="pre">S</span></code> is the length of a single spectra. Now, we have data of shape <code class="docutils literal notranslate"><span class="pre">(P,</span> <span class="pre">N*S)</span></code> where <code class="docutils literal notranslate"><span class="pre">N</span></code> is the number of spectra per position. In order to use most of the code already written above, we need to reshape the data to the shape <code class="docutils literal notranslate"><span class="pre">(P*N,</span> <span class="pre">S)</span></code>. Now, we can easily map the existing <code class="docutils literal notranslate"><span class="pre">map_function()</span></code> on this <code class="docutils literal notranslate"><span class="pre">(P*N,</span> <span class="pre">S)</span></code> dataset.</p>
<p>As far as implementation is concerned, we would need to add the reshaping step to <code class="docutils literal notranslate"><span class="pre">_read_data_chunk()</span></code> as:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">_read_data_chunk</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">PeakFinder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">_read_data_chunk</span><span class="p">()</span>
    <span class="c1"># The above line causes the base Process class to read X pixels from the dataset into self.data</span>
    <span class="c1"># All we need to do now is reshape self.data from (X, N*S) to (X*N, S):</span>
    <span class="c1"># Assuming that we know N (num_spectra) through some metadata:</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span> <span class="n">num_spectra</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p>Recall that <code class="docutils literal notranslate"><span class="pre">_read_data_chunk()</span></code> reads <code class="docutils literal notranslate"><span class="pre">X</span></code> pixels at a time where <code class="docutils literal notranslate"><span class="pre">X</span></code> is the largest number of pixels whose raw data, intermediate products, and results can simultaneously be held in memory. The dataset used for the example above is tractable enough that the entire data is loaded at once, meaning that <code class="docutils literal notranslate"><span class="pre">X</span> <span class="pre">=</span> <span class="pre">P</span></code> in this case.</p>
<p>From here, on, the computation would continue as is but as expected, the results would also consequently be of shape <code class="docutils literal notranslate"><span class="pre">(P*N)</span></code>. We would have to reverse the reshape operation to get back the results in the form: <code class="docutils literal notranslate"><span class="pre">(P,</span> <span class="pre">N)</span></code>. So we would prepend the reverse reshape operation to <code class="docutils literal notranslate"><span class="pre">_write_results_chunk()</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">_write_results_chunk</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="c1"># Recall that the results from the computation are stored in a list called self._results</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_results</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_results</span><span class="p">)</span>  <span class="c1"># convert from list to numpy array</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_results</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_spectra</span><span class="p">)</span>
    <span class="c1"># Now self._results is of shape (P, N) and we can store it in the HDF5 dataset as we did above.</span>
</pre></div>
</div>
</section>
<section id="Computing-on-chunks-instead-of-mapping">
<h3>Computing on chunks instead of mapping<a class="headerlink" href="#Computing-on-chunks-instead-of-mapping" title="Link to this heading">¶</a></h3>
<p>In certain cases, the computation is a little more complex that the <code class="docutils literal notranslate"><span class="pre">map_function()</span></code> cannot directly be mapped to the data. Alternatively, in some cases the <code class="docutils literal notranslate"><span class="pre">map_function()</span></code> needs to mapped multiple times or different sections of the <code class="docutils literal notranslate"><span class="pre">self.data</span></code>. For such cases, the <code class="docutils literal notranslate"><span class="pre">_unit_computation()</span></code> in <code class="docutils literal notranslate"><span class="pre">Process</span></code> provides far more flexibility to the developer. Please see the <code class="docutils literal notranslate"><span class="pre">pycroscopy.processing.SignalFilter</span></code> and <code class="docutils literal notranslate"><span class="pre">BGlib.gmode.analysis.GIVBayesian</span></code> for examples.</p>
<p>By default, <code class="docutils literal notranslate"><span class="pre">_unit_computation()</span></code> maps the <code class="docutils literal notranslate"><span class="pre">map_function()</span></code> to <code class="docutils literal notranslate"><span class="pre">self.data</span></code> using <code class="docutils literal notranslate"><span class="pre">parallel_compute()</span></code> and stores the results in <code class="docutils literal notranslate"><span class="pre">self._results</span></code>. Recall that <code class="docutils literal notranslate"><span class="pre">self.data</span></code> contains data for <code class="docutils literal notranslate"><span class="pre">X</span></code> pixels. For example, <code class="docutils literal notranslate"><span class="pre">_unit_computation()</span></code> in <code class="docutils literal notranslate"><span class="pre">BGlib.gmode.analysis.GIVBayesian</span></code> breaks up the spectra (second axis) of <code class="docutils literal notranslate"><span class="pre">self.data</span></code> into two halves and computes the results separately for each half. <code class="docutils literal notranslate"><span class="pre">_unit_computation()</span></code> for this class calls <code class="docutils literal notranslate"><span class="pre">parallel_compute()</span></code> twice - to map the
<code class="docutils literal notranslate"><span class="pre">map_function()</span></code> to each half of the data chunk. This is a functionality that is challenging to efficiently attain without <code class="docutils literal notranslate"><span class="pre">_unit_computation()</span></code>. Note that when the <code class="docutils literal notranslate"><span class="pre">_unit_computation()</span></code> is overridden, the developer is responsible for the correct usage of <code class="docutils literal notranslate"><span class="pre">parallel_compute()</span></code>, especially passing arguments and keyword arguments.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</div>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="hdf_utils_write.html" class="btn btn-neutral float-left" title="Utilities for writing h5USID files" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2018, Suhas Somnath and Chris R. Smith.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>